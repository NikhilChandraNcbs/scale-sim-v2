printing entry
['Convolution Layer 1', 30, 30, 5, 5, 1, 6, 1, 1, None]
printing entry
['Convolution Layer 2', 10, 10, 5, 5, 6, 16, 1, 1, None]
====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	8x8
SRAM IFMAP (kB): 	1
SRAM Filter (kB): 	1
SRAM OFMAP (kB): 	1
Dataflow: 	Weight Stationary
CSV file path: 	topologies/sparsity/lenet_conv.csv
Bandwidth: 	50
Working in USE USER BANDWIDTH mode.
====================================================

Running Layer 0
self.filter_addr_matrix
(25, 6)
[[100 125 150 175 200 225]
 [101 126 151 176 201 226]
 [102 127 152 177 202 227]
 [103 128 153 178 203 228]
 [104 129 154 179 204 229]
 [105 130 155 180 205 230]
 [106 131 156 181 206 231]
 [107 132 157 182 207 232]
 [108 133 158 183 208 233]
 [109 134 159 184 209 234]
 [110 135 160 185 210 235]
 [111 136 161 186 211 236]
 [112 137 162 187 212 237]
 [113 138 163 188 213 238]
 [114 139 164 189 214 239]
 [115 140 165 190 215 240]
 [116 141 166 191 216 241]
 [117 142 167 192 217 242]
 [118 143 168 193 218 243]
 [119 144 169 194 219 244]
 [120 145 170 195 220 245]
 [121 146 171 196 221 246]
 [122 147 172 197 222 247]
 [123 148 173 198 223 248]
 [124 149 174 199 224 249]]
SPARSITY INSIDE FILTER DEMAND MATRIX CREATION
No sparsity file - creating bitmap
[[1 1 1 1 1 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [1 1 1 1 1 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [1 1 1 1 1 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [1 1 1 1 1 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [1 1 1 1 1 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [1 1 1 1 1 1]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [0 0 0 0 0 0]
 [1 1 1 1 1 1]]
after multiplying
[[100 125 150 175 200 225]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [104 129 154 179 204 229]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [108 133 158 183 208 233]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [112 137 162 187 212 237]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [116 141 166 191 216 241]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [120 145 170 195 220 245]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]
 [124 149 174 199 224 249]]
after reducing the filter array based on sparsity
[[100 104 108 112 116 120 124]
 [125 129 133 137 141 145 149]
 [150 154 158 162 166 170 174]
 [175 179 183 187 191 195 199]
 [200 204 208 212 216 220 224]
 [225 229 233 237 241 245 249]]
Final
[[100 125 150 175 200 225]
 [104 129 154 179 204 229]
 [108 133 158 183 208 233]
 [112 137 162 187 212 237]
 [116 141 166 191 216 241]
 [120 145 170 195 220 245]
 [124 149 174 199 224 249]]
INSIDE INPUT FILTER DEMAND MATRIX CREATION FUNCTION
self.batch_size in ifmap function is  1
self.ifmap_addr_matrix
(676, 25)
[[  0   1   2 ... 122 123 124]
 [  1   2   3 ... 123 124 125]
 [  2   3   4 ... 124 125 126]
 ...
 [773 774 775 ... 895 896 897]
 [774 775 776 ... 896 897 898]
 [775 776 777 ... 897 898 899]]
Input sparsity being applied
1
4
0.25
25 * 0.25 = 7
self.ifmap_addr_matrix for sparsity
[[  0   1   2 ...   4  30  31]
 [  1   2   3 ...   5  31  32]
 [  2   3   4 ...   6  32  33]
 ...
 [773 774 775 ... 777 803 804]
 [774 775 776 ... 778 804 805]
 [775 776 777 ... 779 805 806]]
col_indices
[0 1 2 3 4 5]
self.ofmap_addr_matrix
[[ 200  201  202  203  204  205]
 [ 206  207  208  209  210  211]
 [ 212  213  214  215  216  217]
 ...
 [4238 4239 4240 4241 4242 4243]
 [4244 4245 4246 4247 4248 4249]
 [4250 4251 4252 4253 4254 4255]]
these are the operand matrices
(676, 7)
(7, 6)
(676, 6)
[[  0   1   2 ...   4  30  31]
 [  1   2   3 ...   5  31  32]
 [  2   3   4 ...   6  32  33]
 ...
 [773 774 775 ... 777 803 804]
 [774 775 776 ... 778 804 805]
 [775 776 777 ... 779 805 806]]
[[100 125 150 175 200 225]
 [104 129 154 179 204 229]
 [108 133 158 183 208 233]
 [112 137 162 187 212 237]
 [116 141 166 191 216 241]
 [120 145 170 195 220 245]
 [124 149 174 199 224 249]]
[[ 200  201  202  203  204  205]
 [ 206  207  208  209  210  211]
 [ 212  213  214  215  216  217]
 ...
 [4238 4239 4240 4241 4242 4243]
 [4244 4245 4246 4247 4248 4249]
 [4250 4251 4252 4253 4254 4255]]
layer_calc_params[0] * layer_calc_params[1] * num_filters =  26 26 6
self.num_compute = self.topo.get_layer_num_ofmap_px(self.layer_id) * self.topo.get_layer_window_size(self.layer_id)
Nofmap: Number of OFMAP pixels generated by filter
layer_calc_params[0] * layer_calc_params[1] * num_filters =  26 26 6
101400 = 4056 * 25
self.layer_id  0
filter matrix in create_filter_prefetch_mat
[[100 125 150 175 200 225]
 [104 129 154 179 204 229]
 [108 133 158 183 208 233]
 [112 137 162 187 212 237]
 [116 141 166 191 216 241]
 [120 145 170 195 220 245]
 [124 149 174 199 224 249]]
End
These are the demand matrices
[[-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 ...
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]]
[[ -1.  -1.  -1. ...  -1.  -1.  -1.]
 [124. 149. 174. ... 249.  -1.  -1.]
 [120. 145. 170. ... 245.  -1.  -1.]
 ...
 [ -1.  -1.  -1. ...  -1.  -1.  -1.]
 [ -1.  -1.  -1. ...  -1.  -1.  -1.]
 [ -1.  -1.  -1. ...  -1.  -1.  -1.]]
[[-1.000e+00 -1.000e+00 -1.000e+00 ... -1.000e+00 -1.000e+00 -1.000e+00]
 [-1.000e+00 -1.000e+00 -1.000e+00 ... -1.000e+00 -1.000e+00 -1.000e+00]
 [-1.000e+00 -1.000e+00 -1.000e+00 ... -1.000e+00 -1.000e+00 -1.000e+00]
 ...
 [-1.000e+00 -1.000e+00 -1.000e+00 ...  4.255e+03 -1.000e+00 -1.000e+00]
 [-1.000e+00 -1.000e+00 -1.000e+00 ... -1.000e+00 -1.000e+00 -1.000e+00]
 [-1.000e+00 -1.000e+00 -1.000e+00 ... -1.000e+00 -1.000e+00 -1.000e+00]]
Compute cycles: 697
Stall cycles: 0
Overall utilization: 227.31%
Mapping efficiency: 65.62%
Average IFMAP SRAM BW: 0.115 words/cycle
Average Filter SRAM BW: 0.060 words/cycle
Average Filter Metadata SRAM BW: 0.004 words/cycle
Average OFMAP SRAM BW: 5.819 words/cycle
Average IFMAP DRAM BW: 46.218 words/cycle
Average Filter DRAM BW: 50.000 words/cycle
Average OFMAP DRAM BW: 6.704 words/cycle

Running Layer 1
self.filter_addr_matrix
(150, 16)
[[ 100  250  400 ... 2050 2200 2350]
 [ 101  251  401 ... 2051 2201 2351]
 [ 102  252  402 ... 2052 2202 2352]
 ...
 [ 247  397  547 ... 2197 2347 2497]
 [ 248  398  548 ... 2198 2348 2498]
 [ 249  399  549 ... 2199 2349 2499]]
SPARSITY INSIDE FILTER DEMAND MATRIX CREATION
No sparsity file - creating bitmap
[[1 1 1 ... 1 1 1]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [1 1 1 ... 1 1 1]
 [0 0 0 ... 0 0 0]]
after multiplying
[[ 100  250  400 ... 2050 2200 2350]
 [   0    0    0 ...    0    0    0]
 [   0    0    0 ...    0    0    0]
 ...
 [   0    0    0 ...    0    0    0]
 [ 248  398  548 ... 2198 2348 2498]
 [   0    0    0 ...    0    0    0]]
after reducing the filter array based on sparsity
[[ 100  104  108  112  116  120  124  128  132  136  140  144  148  152
   156  160  164  168  172  176  180  184  188  192  196  200  204  208
   212  216  220  224  228  232  236  240  244  248]
 [ 250  254  258  262  266  270  274  278  282  286  290  294  298  302
   306  310  314  318  322  326  330  334  338  342  346  350  354  358
   362  366  370  374  378  382  386  390  394  398]
 [ 400  404  408  412  416  420  424  428  432  436  440  444  448  452
   456  460  464  468  472  476  480  484  488  492  496  500  504  508
   512  516  520  524  528  532  536  540  544  548]
 [ 550  554  558  562  566  570  574  578  582  586  590  594  598  602
   606  610  614  618  622  626  630  634  638  642  646  650  654  658
   662  666  670  674  678  682  686  690  694  698]
 [ 700  704  708  712  716  720  724  728  732  736  740  744  748  752
   756  760  764  768  772  776  780  784  788  792  796  800  804  808
   812  816  820  824  828  832  836  840  844  848]
 [ 850  854  858  862  866  870  874  878  882  886  890  894  898  902
   906  910  914  918  922  926  930  934  938  942  946  950  954  958
   962  966  970  974  978  982  986  990  994  998]
 [1000 1004 1008 1012 1016 1020 1024 1028 1032 1036 1040 1044 1048 1052
  1056 1060 1064 1068 1072 1076 1080 1084 1088 1092 1096 1100 1104 1108
  1112 1116 1120 1124 1128 1132 1136 1140 1144 1148]
 [1150 1154 1158 1162 1166 1170 1174 1178 1182 1186 1190 1194 1198 1202
  1206 1210 1214 1218 1222 1226 1230 1234 1238 1242 1246 1250 1254 1258
  1262 1266 1270 1274 1278 1282 1286 1290 1294 1298]
 [1300 1304 1308 1312 1316 1320 1324 1328 1332 1336 1340 1344 1348 1352
  1356 1360 1364 1368 1372 1376 1380 1384 1388 1392 1396 1400 1404 1408
  1412 1416 1420 1424 1428 1432 1436 1440 1444 1448]
 [1450 1454 1458 1462 1466 1470 1474 1478 1482 1486 1490 1494 1498 1502
  1506 1510 1514 1518 1522 1526 1530 1534 1538 1542 1546 1550 1554 1558
  1562 1566 1570 1574 1578 1582 1586 1590 1594 1598]
 [1600 1604 1608 1612 1616 1620 1624 1628 1632 1636 1640 1644 1648 1652
  1656 1660 1664 1668 1672 1676 1680 1684 1688 1692 1696 1700 1704 1708
  1712 1716 1720 1724 1728 1732 1736 1740 1744 1748]
 [1750 1754 1758 1762 1766 1770 1774 1778 1782 1786 1790 1794 1798 1802
  1806 1810 1814 1818 1822 1826 1830 1834 1838 1842 1846 1850 1854 1858
  1862 1866 1870 1874 1878 1882 1886 1890 1894 1898]
 [1900 1904 1908 1912 1916 1920 1924 1928 1932 1936 1940 1944 1948 1952
  1956 1960 1964 1968 1972 1976 1980 1984 1988 1992 1996 2000 2004 2008
  2012 2016 2020 2024 2028 2032 2036 2040 2044 2048]
 [2050 2054 2058 2062 2066 2070 2074 2078 2082 2086 2090 2094 2098 2102
  2106 2110 2114 2118 2122 2126 2130 2134 2138 2142 2146 2150 2154 2158
  2162 2166 2170 2174 2178 2182 2186 2190 2194 2198]
 [2200 2204 2208 2212 2216 2220 2224 2228 2232 2236 2240 2244 2248 2252
  2256 2260 2264 2268 2272 2276 2280 2284 2288 2292 2296 2300 2304 2308
  2312 2316 2320 2324 2328 2332 2336 2340 2344 2348]
 [2350 2354 2358 2362 2366 2370 2374 2378 2382 2386 2390 2394 2398 2402
  2406 2410 2414 2418 2422 2426 2430 2434 2438 2442 2446 2450 2454 2458
  2462 2466 2470 2474 2478 2482 2486 2490 2494 2498]]
Final
[[ 100  250  400  550  700  850 1000 1150 1300 1450 1600 1750 1900 2050
  2200 2350]
 [ 104  254  404  554  704  854 1004 1154 1304 1454 1604 1754 1904 2054
  2204 2354]
 [ 108  258  408  558  708  858 1008 1158 1308 1458 1608 1758 1908 2058
  2208 2358]
 [ 112  262  412  562  712  862 1012 1162 1312 1462 1612 1762 1912 2062
  2212 2362]
 [ 116  266  416  566  716  866 1016 1166 1316 1466 1616 1766 1916 2066
  2216 2366]
 [ 120  270  420  570  720  870 1020 1170 1320 1470 1620 1770 1920 2070
  2220 2370]
 [ 124  274  424  574  724  874 1024 1174 1324 1474 1624 1774 1924 2074
  2224 2374]
 [ 128  278  428  578  728  878 1028 1178 1328 1478 1628 1778 1928 2078
  2228 2378]
 [ 132  282  432  582  732  882 1032 1182 1332 1482 1632 1782 1932 2082
  2232 2382]
 [ 136  286  436  586  736  886 1036 1186 1336 1486 1636 1786 1936 2086
  2236 2386]
 [ 140  290  440  590  740  890 1040 1190 1340 1490 1640 1790 1940 2090
  2240 2390]
 [ 144  294  444  594  744  894 1044 1194 1344 1494 1644 1794 1944 2094
  2244 2394]
 [ 148  298  448  598  748  898 1048 1198 1348 1498 1648 1798 1948 2098
  2248 2398]
 [ 152  302  452  602  752  902 1052 1202 1352 1502 1652 1802 1952 2102
  2252 2402]
 [ 156  306  456  606  756  906 1056 1206 1356 1506 1656 1806 1956 2106
  2256 2406]
 [ 160  310  460  610  760  910 1060 1210 1360 1510 1660 1810 1960 2110
  2260 2410]
 [ 164  314  464  614  764  914 1064 1214 1364 1514 1664 1814 1964 2114
  2264 2414]
 [ 168  318  468  618  768  918 1068 1218 1368 1518 1668 1818 1968 2118
  2268 2418]
 [ 172  322  472  622  772  922 1072 1222 1372 1522 1672 1822 1972 2122
  2272 2422]
 [ 176  326  476  626  776  926 1076 1226 1376 1526 1676 1826 1976 2126
  2276 2426]
 [ 180  330  480  630  780  930 1080 1230 1380 1530 1680 1830 1980 2130
  2280 2430]
 [ 184  334  484  634  784  934 1084 1234 1384 1534 1684 1834 1984 2134
  2284 2434]
 [ 188  338  488  638  788  938 1088 1238 1388 1538 1688 1838 1988 2138
  2288 2438]
 [ 192  342  492  642  792  942 1092 1242 1392 1542 1692 1842 1992 2142
  2292 2442]
 [ 196  346  496  646  796  946 1096 1246 1396 1546 1696 1846 1996 2146
  2296 2446]
 [ 200  350  500  650  800  950 1100 1250 1400 1550 1700 1850 2000 2150
  2300 2450]
 [ 204  354  504  654  804  954 1104 1254 1404 1554 1704 1854 2004 2154
  2304 2454]
 [ 208  358  508  658  808  958 1108 1258 1408 1558 1708 1858 2008 2158
  2308 2458]
 [ 212  362  512  662  812  962 1112 1262 1412 1562 1712 1862 2012 2162
  2312 2462]
 [ 216  366  516  666  816  966 1116 1266 1416 1566 1716 1866 2016 2166
  2316 2466]
 [ 220  370  520  670  820  970 1120 1270 1420 1570 1720 1870 2020 2170
  2320 2470]
 [ 224  374  524  674  824  974 1124 1274 1424 1574 1724 1874 2024 2174
  2324 2474]
 [ 228  378  528  678  828  978 1128 1278 1428 1578 1728 1878 2028 2178
  2328 2478]
 [ 232  382  532  682  832  982 1132 1282 1432 1582 1732 1882 2032 2182
  2332 2482]
 [ 236  386  536  686  836  986 1136 1286 1436 1586 1736 1886 2036 2186
  2336 2486]
 [ 240  390  540  690  840  990 1140 1290 1440 1590 1740 1890 2040 2190
  2340 2490]
 [ 244  394  544  694  844  994 1144 1294 1444 1594 1744 1894 2044 2194
  2344 2494]
 [ 248  398  548  698  848  998 1148 1298 1448 1598 1748 1898 2048 2198
  2348 2498]]
INSIDE INPUT FILTER DEMAND MATRIX CREATION FUNCTION
self.batch_size in ifmap function is  1
self.ifmap_addr_matrix
(36, 150)
[[  0   1   2 ... 267 268 269]
 [  6   7   8 ... 273 274 275]
 [ 12  13  14 ... 279 280 281]
 ...
 [318 319 320 ... 585 586 587]
 [324 325 326 ... 591 592 593]
 [330 331 332 ... 597 598 599]]
Input sparsity being applied
1
4
0.25
150 * 0.25 = 38
self.ifmap_addr_matrix for sparsity
[[  0   1   2 ...  65  66  67]
 [  6   7   8 ...  71  72  73]
 [ 12  13  14 ...  77  78  79]
 ...
 [318 319 320 ... 383 384 385]
 [324 325 326 ... 389 390 391]
 [330 331 332 ... 395 396 397]]
col_indices
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]
self.ofmap_addr_matrix
[[200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215]
 [216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231]
 [232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247]
 [248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263]
 [264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279]
 [280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295]
 [296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311]
 [312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327]
 [328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343]
 [344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359]
 [360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375]
 [376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391]
 [392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407]
 [408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423]
 [424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439]
 [440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455]
 [456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471]
 [472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487]
 [488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503]
 [504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519]
 [520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535]
 [536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551]
 [552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567]
 [568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583]
 [584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599]
 [600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615]
 [616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631]
 [632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647]
 [648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663]
 [664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679]
 [680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695]
 [696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711]
 [712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727]
 [728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743]
 [744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759]
 [760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775]]
these are the operand matrices
(36, 38)
(38, 16)
(36, 16)
[[  0   1   2 ...  65  66  67]
 [  6   7   8 ...  71  72  73]
 [ 12  13  14 ...  77  78  79]
 ...
 [318 319 320 ... 383 384 385]
 [324 325 326 ... 389 390 391]
 [330 331 332 ... 395 396 397]]
[[ 100  250  400  550  700  850 1000 1150 1300 1450 1600 1750 1900 2050
  2200 2350]
 [ 104  254  404  554  704  854 1004 1154 1304 1454 1604 1754 1904 2054
  2204 2354]
 [ 108  258  408  558  708  858 1008 1158 1308 1458 1608 1758 1908 2058
  2208 2358]
 [ 112  262  412  562  712  862 1012 1162 1312 1462 1612 1762 1912 2062
  2212 2362]
 [ 116  266  416  566  716  866 1016 1166 1316 1466 1616 1766 1916 2066
  2216 2366]
 [ 120  270  420  570  720  870 1020 1170 1320 1470 1620 1770 1920 2070
  2220 2370]
 [ 124  274  424  574  724  874 1024 1174 1324 1474 1624 1774 1924 2074
  2224 2374]
 [ 128  278  428  578  728  878 1028 1178 1328 1478 1628 1778 1928 2078
  2228 2378]
 [ 132  282  432  582  732  882 1032 1182 1332 1482 1632 1782 1932 2082
  2232 2382]
 [ 136  286  436  586  736  886 1036 1186 1336 1486 1636 1786 1936 2086
  2236 2386]
 [ 140  290  440  590  740  890 1040 1190 1340 1490 1640 1790 1940 2090
  2240 2390]
 [ 144  294  444  594  744  894 1044 1194 1344 1494 1644 1794 1944 2094
  2244 2394]
 [ 148  298  448  598  748  898 1048 1198 1348 1498 1648 1798 1948 2098
  2248 2398]
 [ 152  302  452  602  752  902 1052 1202 1352 1502 1652 1802 1952 2102
  2252 2402]
 [ 156  306  456  606  756  906 1056 1206 1356 1506 1656 1806 1956 2106
  2256 2406]
 [ 160  310  460  610  760  910 1060 1210 1360 1510 1660 1810 1960 2110
  2260 2410]
 [ 164  314  464  614  764  914 1064 1214 1364 1514 1664 1814 1964 2114
  2264 2414]
 [ 168  318  468  618  768  918 1068 1218 1368 1518 1668 1818 1968 2118
  2268 2418]
 [ 172  322  472  622  772  922 1072 1222 1372 1522 1672 1822 1972 2122
  2272 2422]
 [ 176  326  476  626  776  926 1076 1226 1376 1526 1676 1826 1976 2126
  2276 2426]
 [ 180  330  480  630  780  930 1080 1230 1380 1530 1680 1830 1980 2130
  2280 2430]
 [ 184  334  484  634  784  934 1084 1234 1384 1534 1684 1834 1984 2134
  2284 2434]
 [ 188  338  488  638  788  938 1088 1238 1388 1538 1688 1838 1988 2138
  2288 2438]
 [ 192  342  492  642  792  942 1092 1242 1392 1542 1692 1842 1992 2142
  2292 2442]
 [ 196  346  496  646  796  946 1096 1246 1396 1546 1696 1846 1996 2146
  2296 2446]
 [ 200  350  500  650  800  950 1100 1250 1400 1550 1700 1850 2000 2150
  2300 2450]
 [ 204  354  504  654  804  954 1104 1254 1404 1554 1704 1854 2004 2154
  2304 2454]
 [ 208  358  508  658  808  958 1108 1258 1408 1558 1708 1858 2008 2158
  2308 2458]
 [ 212  362  512  662  812  962 1112 1262 1412 1562 1712 1862 2012 2162
  2312 2462]
 [ 216  366  516  666  816  966 1116 1266 1416 1566 1716 1866 2016 2166
  2316 2466]
 [ 220  370  520  670  820  970 1120 1270 1420 1570 1720 1870 2020 2170
  2320 2470]
 [ 224  374  524  674  824  974 1124 1274 1424 1574 1724 1874 2024 2174
  2324 2474]
 [ 228  378  528  678  828  978 1128 1278 1428 1578 1728 1878 2028 2178
  2328 2478]
 [ 232  382  532  682  832  982 1132 1282 1432 1582 1732 1882 2032 2182
  2332 2482]
 [ 236  386  536  686  836  986 1136 1286 1436 1586 1736 1886 2036 2186
  2336 2486]
 [ 240  390  540  690  840  990 1140 1290 1440 1590 1740 1890 2040 2190
  2340 2490]
 [ 244  394  544  694  844  994 1144 1294 1444 1594 1744 1894 2044 2194
  2344 2494]
 [ 248  398  548  698  848  998 1148 1298 1448 1598 1748 1898 2048 2198
  2348 2498]]
[[200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215]
 [216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231]
 [232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247]
 [248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263]
 [264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279]
 [280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295]
 [296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311]
 [312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327]
 [328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343]
 [344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359]
 [360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375]
 [376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391]
 [392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407]
 [408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423]
 [424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439]
 [440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455]
 [456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471]
 [472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487]
 [488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503]
 [504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519]
 [520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535]
 [536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551]
 [552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567]
 [568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583]
 [584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599]
 [600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615]
 [616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631]
 [632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647]
 [648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663]
 [664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679]
 [680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695]
 [696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711]
 [712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727]
 [728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743]
 [744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759]
 [760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775]]
layer_calc_params[0] * layer_calc_params[1] * num_filters =  6 6 16
self.num_compute = self.topo.get_layer_num_ofmap_px(self.layer_id) * self.topo.get_layer_window_size(self.layer_id)
Nofmap: Number of OFMAP pixels generated by filter
layer_calc_params[0] * layer_calc_params[1] * num_filters =  6 6 16
86400 = 576 * 150
self.layer_id  1
filter matrix in create_filter_prefetch_mat
[[ 100  250  400  550  700  850 1000 1150 1300 1450 1600 1750 1900 2050
  2200 2350]
 [ 104  254  404  554  704  854 1004 1154 1304 1454 1604 1754 1904 2054
  2204 2354]
 [ 108  258  408  558  708  858 1008 1158 1308 1458 1608 1758 1908 2058
  2208 2358]
 [ 112  262  412  562  712  862 1012 1162 1312 1462 1612 1762 1912 2062
  2212 2362]
 [ 116  266  416  566  716  866 1016 1166 1316 1466 1616 1766 1916 2066
  2216 2366]
 [ 120  270  420  570  720  870 1020 1170 1320 1470 1620 1770 1920 2070
  2220 2370]
 [ 124  274  424  574  724  874 1024 1174 1324 1474 1624 1774 1924 2074
  2224 2374]
 [ 128  278  428  578  728  878 1028 1178 1328 1478 1628 1778 1928 2078
  2228 2378]
 [ 132  282  432  582  732  882 1032 1182 1332 1482 1632 1782 1932 2082
  2232 2382]
 [ 136  286  436  586  736  886 1036 1186 1336 1486 1636 1786 1936 2086
  2236 2386]
 [ 140  290  440  590  740  890 1040 1190 1340 1490 1640 1790 1940 2090
  2240 2390]
 [ 144  294  444  594  744  894 1044 1194 1344 1494 1644 1794 1944 2094
  2244 2394]
 [ 148  298  448  598  748  898 1048 1198 1348 1498 1648 1798 1948 2098
  2248 2398]
 [ 152  302  452  602  752  902 1052 1202 1352 1502 1652 1802 1952 2102
  2252 2402]
 [ 156  306  456  606  756  906 1056 1206 1356 1506 1656 1806 1956 2106
  2256 2406]
 [ 160  310  460  610  760  910 1060 1210 1360 1510 1660 1810 1960 2110
  2260 2410]
 [ 164  314  464  614  764  914 1064 1214 1364 1514 1664 1814 1964 2114
  2264 2414]
 [ 168  318  468  618  768  918 1068 1218 1368 1518 1668 1818 1968 2118
  2268 2418]
 [ 172  322  472  622  772  922 1072 1222 1372 1522 1672 1822 1972 2122
  2272 2422]
 [ 176  326  476  626  776  926 1076 1226 1376 1526 1676 1826 1976 2126
  2276 2426]
 [ 180  330  480  630  780  930 1080 1230 1380 1530 1680 1830 1980 2130
  2280 2430]
 [ 184  334  484  634  784  934 1084 1234 1384 1534 1684 1834 1984 2134
  2284 2434]
 [ 188  338  488  638  788  938 1088 1238 1388 1538 1688 1838 1988 2138
  2288 2438]
 [ 192  342  492  642  792  942 1092 1242 1392 1542 1692 1842 1992 2142
  2292 2442]
 [ 196  346  496  646  796  946 1096 1246 1396 1546 1696 1846 1996 2146
  2296 2446]
 [ 200  350  500  650  800  950 1100 1250 1400 1550 1700 1850 2000 2150
  2300 2450]
 [ 204  354  504  654  804  954 1104 1254 1404 1554 1704 1854 2004 2154
  2304 2454]
 [ 208  358  508  658  808  958 1108 1258 1408 1558 1708 1858 2008 2158
  2308 2458]
 [ 212  362  512  662  812  962 1112 1262 1412 1562 1712 1862 2012 2162
  2312 2462]
 [ 216  366  516  666  816  966 1116 1266 1416 1566 1716 1866 2016 2166
  2316 2466]
 [ 220  370  520  670  820  970 1120 1270 1420 1570 1720 1870 2020 2170
  2320 2470]
 [ 224  374  524  674  824  974 1124 1274 1424 1574 1724 1874 2024 2174
  2324 2474]
 [ 228  378  528  678  828  978 1128 1278 1428 1578 1728 1878 2028 2178
  2328 2478]
 [ 232  382  532  682  832  982 1132 1282 1432 1582 1732 1882 2032 2182
  2332 2482]
 [ 236  386  536  686  836  986 1136 1286 1436 1586 1736 1886 2036 2186
  2336 2486]
 [ 240  390  540  690  840  990 1140 1290 1440 1590 1740 1890 2040 2190
  2340 2490]
 [ 244  394  544  694  844  994 1144 1294 1444 1594 1744 1894 2044 2194
  2344 2494]
 [ 248  398  548  698  848  998 1148 1298 1448 1598 1748 1898 2048 2198
  2348 2498]]
End
These are the demand matrices
[[-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 ...
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]
 [-1. -1. -1. ... -1. -1. -1.]]
[[ 1.280e+02  2.780e+02  4.280e+02 ...  8.780e+02  1.028e+03  1.178e+03]
 [ 1.240e+02  2.740e+02  4.240e+02 ...  8.740e+02  1.024e+03  1.174e+03]
 [ 1.200e+02  2.700e+02  4.200e+02 ...  8.700e+02  1.020e+03  1.170e+03]
 ...
 [-1.000e+00 -1.000e+00 -1.000e+00 ... -1.000e+00 -1.000e+00 -1.000e+00]
 [-1.000e+00 -1.000e+00 -1.000e+00 ... -1.000e+00 -1.000e+00 -1.000e+00]
 [-1.000e+00 -1.000e+00 -1.000e+00 ... -1.000e+00 -1.000e+00 -1.000e+00]]
[[ -1.  -1.  -1. ...  -1.  -1.  -1.]
 [ -1.  -1.  -1. ...  -1.  -1.  -1.]
 [ -1.  -1.  -1. ...  -1.  -1.  -1.]
 ...
 [ -1.  -1.  -1. ... 773. 758. 743.]
 [ -1.  -1.  -1. ...  -1. 774. 759.]
 [ -1.  -1.  -1. ...  -1.  -1. 775.]]
Compute cycles: 579
Stall cycles: 0
Overall utilization: 233.16%
Mapping efficiency: 95.00%
Average IFMAP SRAM BW: 1.382 words/cycle
Average Filter SRAM BW: 1.050 words/cycle
Average Filter Metadata SRAM BW: 0.066 words/cycle
Average OFMAP SRAM BW: 4.974 words/cycle
Average IFMAP DRAM BW: 46.479 words/cycle
Average Filter DRAM BW: 47.826 words/cycle
Average OFMAP DRAM BW: 5.975 words/cycle
************ SCALE SIM Run Complete ****************
